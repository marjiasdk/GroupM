{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-nBzLi1B6Jt"
      },
      "source": [
        "# Importing libraries and modules (Data Collection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAODQ1fdBjP7"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries and modules necessary for our classification model.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0dpxVChCChB"
      },
      "outputs": [],
      "source": [
        "# Storing the dataset into a data frame variable.\n",
        "\n",
        "data_frame = pd.read_csv('Dataset_7.csv')\n",
        "data_frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEcoOetLDrRu"
      },
      "source": [
        "# Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97yDOdiRDwGt"
      },
      "outputs": [],
      "source": [
        "# 1. Taking care of missing data in the dataset.\n",
        "\n",
        "# Attaining the sum of empty/missing values.\n",
        "missing_values = data_frame.isnull().sum().sum()\n",
        "\n",
        "if missing_values == 0:\n",
        "  print(\"There is no missing data in the dataset.\")\n",
        "else:\n",
        "  data_frame.dropna(inplace=True) # Dropping the missing entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW1IvgKVTQxh"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Function to clean symptom names dynamically (regular expressions)\n",
        "def clean_symptoms(symptoms):\n",
        "    # Removing trailing numeric suffixes and unwanted symbols\n",
        "    return [re.sub(r'\\d+$', '', re.sub(r'[^\\w\\s]', '', symptom.strip())) for symptom in symptoms]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9F8AzCnEB9g"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer  # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html\n",
        "\n",
        "\"\"\"\n",
        "# 2. Applying MultiLabelBinarizer (version of multi-labeled one-hot encoding)\n",
        "   - Used for encoding multi-labeled categorical data (e.g., multiple symptoms).\n",
        "\"\"\"\n",
        "# Initialize MultiLabelBinarizer for multi-labeled one-hot encoding\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "# Splitting the symptoms column into lists for encoding\n",
        "# Clean_symptoms is assumed to handle any preprocessing such as trimming or standardization\n",
        "query_symptom_column = data_frame['Symptom'].str.split(',').apply(lambda x: clean_symptoms(x))\n",
        "\n",
        "# Using MultiLabelBinarizer for encoding\n",
        "query_encoded = mlb.fit_transform(query_symptom_column)\n",
        "\n",
        "# Extracting the encoded column names from MultiLabelBinarizer\n",
        "encoded_columns = mlb.classes_\n",
        "\n",
        "# Converting the encoded data back to a DataFrame for better visualization\n",
        "query_encoded_df = pd.DataFrame(query_encoded, columns=encoded_columns)\n",
        "\n",
        "# Concatenating the one-hot encoded symptoms back to the original dataset\n",
        "# Replacing the original 'Symptom' column with the encoded features\n",
        "data_frame = pd.concat([data_frame.drop(columns=['Symptom']), query_encoded_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro_SoP6rW15B"
      },
      "outputs": [],
      "source": [
        "# Ensuring the 'Disease' column is the last column (as it is the label)\n",
        "columns = [col for col in data_frame.columns if col != 'Disease'] + ['Disease']\n",
        "data_frame = data_frame[columns]\n",
        "data_frame.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "data_frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q34751wQVZp4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPMe0E55XM6w"
      },
      "outputs": [],
      "source": [
        "# Converting the data frame into a numpy array.\n",
        "\n",
        "numpy_array = data_frame.to_numpy()\n",
        "numpy_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSbrk5OAYHFK"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into training set and testing set (70/30 split)\n",
        "from sklearn.model_selection import train_test_split  # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "X = data_frame.drop(columns=['Disease'])  # Features\n",
        "y = data_frame['Disease']  # Label\n",
        "\n",
        "# 70/30 split, where stratify ensures the class distribution remains consistent across splits\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# Confirming the class distribution in training and testing sets\n",
        "# Useful for verifying that the stratify parameter preserved class proportions\n",
        "train_distribution = y_train.value_counts()\n",
        "test_distribution = y_test.value_counts()\n",
        "\n",
        "print(\"Training Set Distribution:\\n\", train_distribution)\n",
        "print(\"\\nTesting Set Distribution:\\n\", test_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_ba2e1jZ4ch"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbhEeAclcBl8"
      },
      "outputs": [],
      "source": [
        "# Importing metrics for prediction results\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "# References:\n",
        "# - Classification Report: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
        "# - Confusion Matrix: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "# - Accuracy Score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
        "# - F1 Score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzaEu73raSmB"
      },
      "source": [
        "## First Model (Decision Trees)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5Yw9_R9Z-FR"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier  # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "# Reference for metrics: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "# Initialising the Decision Tree Classifier\n",
        "dt_model = DecisionTreeClassifier(random_state=42)  # Decision Tree with default parameters\n",
        "\n",
        "# Training the model\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "dt_predictions = dt_model.predict(X_test)\n",
        "\n",
        "# Evaluate on training data\n",
        "train_predictions = dt_model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "\n",
        "# Evaluate on testing data\n",
        "test_predictions = dt_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(\"Testing Accuracy:\", test_accuracy)\n",
        "\n",
        "# Compare results\n",
        "# Overfitting check: A large difference between training and testing accuracy indicates overfitting.\n",
        "if train_accuracy - test_accuracy > 0.1:  # Example threshold\n",
        "    print(\"Potentially Overfitted\")\n",
        "else:\n",
        "    print(\"Model appears to generalize well.\")\n",
        "\n",
        "# Actual and predicted classes for F1-score calculation\n",
        "y_true = [\"panic disorder\", \"acute pancreatitis\", \"asthma\", \"heart attack\"]\n",
        "y_pred = [\"panic disorder\", \"acute pancreatitis\", \"heart attack\", \"asthma\"]\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, dt_predictions))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, dt_predictions))  # Scikit-learn documentation\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, dt_predictions))  # Scikit-learn documentation\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')  # Scikit-learn documentation\n",
        "print(f\"F1-Score (Macro): {f1_macro:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnYahoqhgey5"
      },
      "source": [
        "# Second Model (Random Forest Classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNvyehpdg4gH"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier  # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "# Reference for metrics: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "# Initialising the Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)  # Random Forest with default parameters\n",
        "\n",
        "# Training the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluating on training data\n",
        "rf_train_predictions = rf_model.predict(X_train)\n",
        "rf_train_accuracy = accuracy_score(y_train, rf_train_predictions)\n",
        "print(\"Training Accuracy:\", rf_train_accuracy)\n",
        "\n",
        "# Evaluating on testing data\n",
        "rf_test_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(\"Testing Accuracy:\", rf_test_accuracy)\n",
        "\n",
        "# Checking for potential overfitting\n",
        "# Overfitting check: A large difference between training and testing accuracy indicates overfitting.\n",
        "if rf_train_accuracy - rf_test_accuracy > 0.1:\n",
        "    print(\"Potentially Overfitted\")\n",
        "else:\n",
        "    print(\"Model appears to generalize well.\")\n",
        "\n",
        "# Actual and predicted classes for F1-score calculation\n",
        "y_true = [\"panic disorder\", \"acute pancreatitis\", \"asthma\", \"heart attack\"]\n",
        "y_pred = [\"panic disorder\", \"acute pancreatitis\", \"heart attack\", \"asthma\"]\n",
        "\n",
        "# Evaluate overall model performance\n",
        "print(\"\\nAccuracy:\", rf_test_accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, rf_predictions))  # Scikit-learn documentation\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, rf_predictions))  # Scikit-learn documentation\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')  # Scikit-learn documentation\n",
        "print(f\"F1-Score (Macro): {f1_macro:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs0VWa93hqKg"
      },
      "source": [
        "# Third Model (Support Vector Machines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5T3AGTXh78d"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC  # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "# Reference for metrics: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "# Initializing the Support Vector Machine Classifier\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)  # Radial Basis Function kernel is used by default\n",
        "\n",
        "# Training the model\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluating on training data\n",
        "svm_train_predictions = svm_model.predict(X_train)\n",
        "svm_train_accuracy = accuracy_score(y_train, svm_train_predictions)\n",
        "print(\"Training Accuracy:\", svm_train_accuracy)\n",
        "\n",
        "# Evaluating on testing data\n",
        "svm_test_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "print(\"Testing Accuracy:\", svm_test_accuracy)\n",
        "\n",
        "# Checking for potential overfitting\n",
        "# Overfitting check: A large difference between training and testing accuracy indicates overfitting.\n",
        "if svm_train_accuracy - svm_test_accuracy > 0.1:\n",
        "    print(\"Potentially Overfitted\")\n",
        "else:\n",
        "    print(\"Model appears to generalize well.\")\n",
        "\n",
        "# Actual and predicted classes for F1-score calculation\n",
        "y_true = [\"panic disorder\", \"acute pancreatitis\", \"asthma\", \"heart attack\"]\n",
        "y_pred = [\"panic disorder\", \"acute pancreatitis\", \"heart attack\", \"asthma\"]\n",
        "\n",
        "# Evaluate overall model performance\n",
        "print(\"\\nAccuracy:\", svm_test_accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, svm_predictions))  # Scikit-learn documentation\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, svm_predictions))  # Scikit-learn documentation\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')  # Scikit-learn documentation\n",
        "print(f\"F1-Score (Macro): {f1_macro:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oVZzq5QjYEw"
      },
      "source": [
        "# Fourth Model (K-Nearest Neighbours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8rap59djo4v"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier  # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "# Reference for metrics: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "# Initializing the K-Nearest Neighbors Classifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)  # Uses the default distance metric (Minkowski)\n",
        "\n",
        "# Training the model\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "knn_predictions = knn_model.predict(X_test)\n",
        "\n",
        "# Evaluating on training data\n",
        "knn_train_predictions = knn_model.predict(X_train)\n",
        "knn_train_accuracy = accuracy_score(y_train, knn_train_predictions)\n",
        "print(\"Training Accuracy:\", knn_train_accuracy)\n",
        "\n",
        "# Evaluating on testing data\n",
        "knn_test_accuracy = accuracy_score(y_test, knn_predictions)\n",
        "print(\"Testing Accuracy:\", knn_test_accuracy)\n",
        "\n",
        "# Checking for potential overfitting\n",
        "# Overfitting check: A large difference between training and testing accuracy indicates overfitting.\n",
        "if knn_train_accuracy - knn_test_accuracy > 0.1:\n",
        "    print(\"Potentially Overfitted\")\n",
        "else:\n",
        "    print(\"Model appears to generalize well.\")\n",
        "\n",
        "# Actual and predicted classes for F1-score calculation\n",
        "y_true = [\"panic disorder\", \"acute pancreatitis\", \"asthma\", \"heart attack\"]\n",
        "y_pred = [\"panic disorder\", \"acute pancreatitis\", \"heart attack\", \"asthma\"]\n",
        "\n",
        "# Evaluate overall model performance\n",
        "print(\"\\nAccuracy:\", knn_test_accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, knn_predictions))  # Scikit-learn documentation\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, knn_predictions))  # Scikit-learn documentation\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')  # Scikit-learn documentation\n",
        "print(f\"F1-Score (Macro): {f1_macro:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v71m3I5vk2As"
      },
      "source": [
        "# Fifth Model (Naive Bayes Classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewy4Ggodk07P"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB  # Reference: https://scikit-learn.org/stable/modules/naive_bayes.html\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "# Reference for metrics: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "# Initializing the Naive Bayes Classifier\n",
        "nb_model = GaussianNB()\n",
        "\n",
        "# Training the model\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "nb_predictions = nb_model.predict(X_test)\n",
        "\n",
        "# Evaluating on training data\n",
        "nb_train_predictions = nb_model.predict(X_train)\n",
        "nb_train_accuracy = accuracy_score(y_train, nb_train_predictions)\n",
        "print(\"Training Accuracy:\", nb_train_accuracy)\n",
        "\n",
        "# Evaluating on testing data\n",
        "nb_test_accuracy = accuracy_score(y_test, nb_predictions)\n",
        "print(\"Testing Accuracy:\", nb_test_accuracy)\n",
        "\n",
        "# Checking for potential overfitting\n",
        "if nb_train_accuracy - nb_test_accuracy > 0.1:\n",
        "    print(\"Potentially Overfitted\")\n",
        "else:\n",
        "    print(\"Model appears to generalize well.\")\n",
        "\n",
        "# Actual and predicted classes for F1-score calculation\n",
        "y_true = [\"panic disorder\", \"acute pancreatitis\", \"asthma\", \"heart attack\"]\n",
        "y_pred = [\"panic disorder\", \"acute pancreatitis\", \"heart attack\", \"asthma\"]\n",
        "\n",
        "# Evaluate overall model performance\n",
        "print(\"\\nAccuracy:\", nb_test_accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, nb_predictions))  # Scikit-learn documentation\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, nb_predictions))  # Scikit-learn documentation\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')  # Scikit-learn documentation\n",
        "print(f\"F1-Score (Macro): {f1_macro:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}