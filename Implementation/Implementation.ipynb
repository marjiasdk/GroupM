{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-nBzLi1B6Jt"
      },
      "source": [
        "# Importing libraries and modules (Data Collection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAODQ1fdBjP7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Importing the necessary modules to begin creating our model.\n",
        "\n",
        "1. Numpy (for array conversion)\n",
        "2. Pandas (for reading the csv and other operations)\n",
        "3. Matplotlib (for graph repreentation)\n",
        "4. Seaborn (for graph representation)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0dpxVChCChB"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "We then store the dataset into a variable to utilise for future operations called \"data_frame\"\n",
        "\"\"\"\n",
        "data_frame = pd.read_csv('Dataset_7.csv')\n",
        "data_frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEcoOetLDrRu"
      },
      "source": [
        "# Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "97yDOdiRDwGt"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data_frame' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mThe code cell here takes care of handling missing/empty values\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39m  - If there are missing values, then we drop the the missing values from the dataset inplace.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m# 1. Taking care of missing data in the dataset.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[39m# Attaining the sum of empty/missing values.\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m missing_values \u001b[39m=\u001b[39m data_frame\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39msum()\n\u001b[0;32m     15\u001b[0m \u001b[39mif\u001b[39;00m missing_values \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     16\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThere is no missing data in the dataset.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'data_frame' is not defined"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "The code cell here takes care of handling missing/empty values\n",
        "\n",
        "1. The amount of missing/empty values are first attained\n",
        "2. An if statement is inserted to see if there are missing values.\n",
        "  - If there is missing values, then we notify to the console saying there's no missing values.\n",
        "  - If there are missing values, then we drop the the missing values from the dataset inplace.\n",
        "\"\"\"\n",
        "\n",
        "# 1. Taking care of missing data in the dataset.\n",
        "\n",
        "# Attaining the sum of empty/missing values.\n",
        "missing_values = data_frame.isnull().sum().sum()\n",
        "\n",
        "if missing_values == 0:\n",
        "  print(\"There is no missing data in the dataset.\")\n",
        "else:\n",
        "  data_frame.dropna(inplace=True) # Dropping the missing entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW1IvgKVTQxh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The module \"re\" is then imported for the use of regular expressions\n",
        "\n",
        "Function: clean_sytmptoms\n",
        "Argument: symptoms\n",
        "Return Value: A filtered list of symptoms, ridding of any mistakes/typos present in symptoms.\n",
        "\n",
        "This is ran through as a lambda function in the next cell.\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "\n",
        "# Function to clean symptom names dynamically (regular expressions)\n",
        "def clean_symptoms(symptoms):\n",
        "    # Removing trailing numeric suffixes and unwanted symbols\n",
        "    return [re.sub(r'\\d+$', '', re.sub(r'[^\\w\\s]', '', symptom.strip())) for symptom in symptoms]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9F8AzCnEB9g"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "The multi label binarizer module is then imported in order to incorporate one-hot encoding \n",
        "on multiple labels\n",
        "\n",
        "These labels will be the unique symptoms listed in the data entries, where they will be converted to\n",
        "features. This means that each symptom will be its own feature with binary values dictating whether they're present or no.\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer  # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html\n",
        "\n",
        "\"\"\"\n",
        "# 2. Applying MultiLabelBinarizer (version of multi-labeled one-hot encoding)\n",
        "   - Used for encoding multi-labeled categorical data (e.g., multiple symptoms).\n",
        "\"\"\"\n",
        "# Initialize MultiLabelBinarizer for multi-labeled one-hot encoding\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "# Splitting the symptoms column into lists for encoding\n",
        "# Clean_symptoms is assumed to handle any preprocessing such as trimming or standardization\n",
        "query_symptom_column = data_frame['Symptom'].str.split(',').apply(lambda x: clean_symptoms(x))\n",
        "\n",
        "# Using MultiLabelBinarizer for encoding\n",
        "query_encoded = mlb.fit_transform(query_symptom_column)\n",
        "\n",
        "# Extracting the encoded column names from MultiLabelBinarizer\n",
        "encoded_columns = mlb.classes_\n",
        "\n",
        "# Converting the encoded data back to a DataFrame for better visualization\n",
        "query_encoded_df = pd.DataFrame(query_encoded, columns=encoded_columns)\n",
        "\n",
        "# Concatenating the one-hot encoded symptoms back to the original dataset\n",
        "# Replacing the original 'Symptom' column with the encoded features\n",
        "data_frame = pd.concat([data_frame.drop(columns=['Symptom']), query_encoded_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro_SoP6rW15B"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "At this point, the layout of the dataset consists of the label followed by the features.\n",
        "\n",
        "The code below reverses this, where the label will be last in the data_frame, while the features will be displayed first\n",
        "\n",
        "On top of this, the column \"Unnamed: 0\" is dropped, as it adds no significant value and just contains indexing, which is already\n",
        "automated in jupyter.\n",
        "\"\"\"\n",
        "\n",
        "# Ensuring the 'Disease' column is the last column (as it is the label)\n",
        "columns = [col for col in data_frame.columns if col != 'Disease'] + ['Disease']\n",
        "data_frame = data_frame[columns]\n",
        "data_frame.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "data_frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q34751wQVZp4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPMe0E55XM6w"
      },
      "outputs": [],
      "source": [
        "# Converting the data frame into a numpy array.\n",
        "\n",
        "numpy_array = data_frame.to_numpy()\n",
        "numpy_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rSbrk5OAYHFK"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\" \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mThe train_test_split module is then imported in to split the dataset into training and testing sets.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[39mThis split is done using a 70/30 split, where the parameters are modified with the modified:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# Splitting the dataset into training set and testing set (70/30 split)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split  \u001b[39m# Reference: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\u001b[39;00m\n\u001b[0;32m     10\u001b[0m X \u001b[39m=\u001b[39m data_frame\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mDisease\u001b[39m\u001b[39m'\u001b[39m])  \u001b[39m# Features\u001b[39;00m\n\u001b[0;32m     11\u001b[0m y \u001b[39m=\u001b[39m data_frame[\u001b[39m'\u001b[39m\u001b[39mDisease\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Label\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "\"\"\" \n",
        "The train_test_split module is then imported in to split the dataset into training and testing sets.\n",
        "\n",
        "This split is done using a 70/30 split, where the parameters are modified with the modified:\n",
        "    - stratify: Which balances the split between classes.\n",
        "    - random_state: Which randomises the split.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Splitting the dataset into training set and testing set (70/30 split)\n",
        "from sklearn.model_selection import train_test_split  # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "X = data_frame.drop(columns=['Disease'])  # Features\n",
        "y = data_frame['Disease']  # Label\n",
        "\n",
        "# 70/30 split, where stratify ensures the class distribution remains consistent across splits\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# Confirming the class distribution in training and testing sets\n",
        "# Useful for verifying that the stratify parameter preserved class proportions\n",
        "train_distribution = y_train.value_counts()\n",
        "test_distribution = y_test.value_counts()\n",
        "\n",
        "print(\"Training Set Distribution:\\n\", train_distribution)\n",
        "print(\"\\nTesting Set Distribution:\\n\", test_distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_ba2e1jZ4ch"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbhEeAclcBl8"
      },
      "outputs": [],
      "source": [
        "# Importing metrics for prediction results\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "# References:\n",
        "# - Classification Report: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
        "# - Confusion Matrix: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "# - Accuracy Score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
        "# - F1 Score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzaEu73raSmB"
      },
      "source": [
        "## First Model (Decision Trees)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e5Yw9_R9Z-FR"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mDecisionTreeClassifier is imported in to use as the first machine learning model.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m \u001b[39mimport\u001b[39;00m DecisionTreeClassifier  \u001b[39m# Reference: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score, classification_report, confusion_matrix, f1_score\n\u001b[0;32m      7\u001b[0m \u001b[39m# Reference for metrics: https://scikit-learn.org/stable/modules/model_evaluation.html\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[39m# Initialising the Decision Tree Classifier\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "DecisionTreeClassifier is imported in to use as the first machine learning model.\n",
        "Other modules from the sklearn.metrics package is used to import metric evaluation modules.\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier  # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "# Reference for metrics: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "# Initialising the Decision Tree Classifier\n",
        "dt_model = DecisionTreeClassifier(random_state=42)  # Decision Tree with default parameters\n",
        "\n",
        "# Training the model\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "dt_predictions = dt_model.predict(X_test)\n",
        "\n",
        "# Evaluate on training data\n",
        "train_predictions = dt_model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "\n",
        "# Evaluate on testing data\n",
        "test_predictions = dt_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(\"Testing Accuracy:\", test_accuracy)\n",
        "\n",
        "# Compare results\n",
        "# Overfitting check: A large difference between training and testing accuracy indicates overfitting.\n",
        "if train_accuracy - test_accuracy > 0.1:  # Example threshold\n",
        "    print(\"Potentially Overfitted\")\n",
        "else:\n",
        "    print(\"Model appears to generalize well.\")\n",
        "\n",
        "# Actual and predicted classes for F1-score calculation\n",
        "y_true = [\"panic disorder\", \"acute pancreatitis\", \"asthma\", \"heart attack\"]\n",
        "y_pred = [\"panic disorder\", \"acute pancreatitis\", \"heart attack\", \"asthma\"]\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, dt_predictions))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, dt_predictions))  # Scikit-learn documentation\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, dt_predictions))  # Scikit-learn documentation\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')  # Scikit-learn documentation\n",
        "print(f\"F1-Score (Macro): {f1_macro:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs0VWa93hqKg"
      },
      "source": [
        "# Second Model (Support Vector Machines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5T3AGTXh78d"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "DecisionTreeClassifier is imported in to use as the first machine learning model.\n",
        "Other modules from the sklearn.metrics package is used to import metric evaluation modules.\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.svm import SVC  # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "# Reference for metrics: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "# Initializing the Support Vector Machine Classifier\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)  # Radial Basis Function kernel is used by default\n",
        "\n",
        "# Training the model\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluating on training data\n",
        "svm_train_predictions = svm_model.predict(X_train)\n",
        "svm_train_accuracy = accuracy_score(y_train, svm_train_predictions)\n",
        "print(\"Training Accuracy:\", svm_train_accuracy)\n",
        "\n",
        "# Evaluating on testing data\n",
        "svm_test_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "print(\"Testing Accuracy:\", svm_test_accuracy)\n",
        "\n",
        "# Checking for potential overfitting\n",
        "# Overfitting check: A large difference between training and testing accuracy indicates overfitting.\n",
        "if svm_train_accuracy - svm_test_accuracy > 0.1:\n",
        "    print(\"Potentially Overfitted\")\n",
        "else:\n",
        "    print(\"Model appears to generalize well.\")\n",
        "\n",
        "# Actual and predicted classes for F1-score calculation\n",
        "y_true = [\"panic disorder\", \"acute pancreatitis\", \"asthma\", \"heart attack\"]\n",
        "y_pred = [\"panic disorder\", \"acute pancreatitis\", \"heart attack\", \"asthma\"]\n",
        "\n",
        "# Evaluate overall model performance\n",
        "print(\"\\nAccuracy:\", svm_test_accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, svm_predictions))  # Scikit-learn documentation\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, svm_predictions))  # Scikit-learn documentation\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')  # Scikit-learn documentation\n",
        "print(f\"F1-Score (Macro): {f1_macro:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oVZzq5QjYEw"
      },
      "source": [
        "# Third Model (K-Nearest Neighbours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8rap59djo4v"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "KNeighboursClassifier is imported in to use as the second machine learning model with neighbours being set to 5.\n",
        "Other modules from the sklearn.metrics package is used to import metric evaluation modules.\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier  # Reference: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "# Reference for metrics: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "# Initializing the K-Nearest Neighbors Classifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)  # Uses the default distance metric (Minkowski)\n",
        "\n",
        "# Training the model\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "knn_predictions = knn_model.predict(X_test)\n",
        "\n",
        "# Evaluating on training data\n",
        "knn_train_predictions = knn_model.predict(X_train)\n",
        "knn_train_accuracy = accuracy_score(y_train, knn_train_predictions)\n",
        "print(\"Training Accuracy:\", knn_train_accuracy)\n",
        "\n",
        "# Evaluating on testing data\n",
        "knn_test_accuracy = accuracy_score(y_test, knn_predictions)\n",
        "print(\"Testing Accuracy:\", knn_test_accuracy)\n",
        "\n",
        "# Checking for potential overfitting\n",
        "# Overfitting check: A large difference between training and testing accuracy indicates overfitting.\n",
        "if knn_train_accuracy - knn_test_accuracy > 0.1:\n",
        "    print(\"Potentially Overfitted\")\n",
        "else:\n",
        "    print(\"Model appears to generalize well.\")\n",
        "\n",
        "# Actual and predicted classes for F1-score calculation\n",
        "y_true = [\"panic disorder\", \"acute pancreatitis\", \"asthma\", \"heart attack\"]\n",
        "y_pred = [\"panic disorder\", \"acute pancreatitis\", \"heart attack\", \"asthma\"]\n",
        "\n",
        "# Evaluate overall model performance\n",
        "print(\"\\nAccuracy:\", knn_test_accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, knn_predictions))  # Scikit-learn documentation\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, knn_predictions))  # Scikit-learn documentation\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')  # Scikit-learn documentation\n",
        "print(f\"F1-Score (Macro): {f1_macro:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
